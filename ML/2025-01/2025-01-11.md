# Quantum Comb Tomography via Learning Isometries on Stiefel Manifold

## 通过在Stiefel流形上学习等距的量子梳状层析成像

Link: http://link.aps.org/doi/10.1103/PhysRevLett.134.010803

**Authors:** Ze-Tong Li, Xin-Lin He, Cong-Cong Zheng, Yu-Qian Dong, Tian Luan, Xu-Tao Yu, and Zai-Chen Zhang

Author(s): Ze-Tong Li, Xin-Lin He, Cong-Cong Zheng, Yu-Qian Dong, Tian Luan, Xu-Tao Yu, and Zai-Chen Zhang<br /><p>Explicit mathematical reconstructions of quantum combs play a significant role in developing quantum information science. However, tremendous parameter requirements and physical constraint implementations have become computationally nonignorable encumbrances. In this Letter, we propose an efficient …</p><br />[Phys. Rev. Lett. 134, 010803] Published Fri Jan 10, 2025


---
# High-performance ternary logic circuits and neural networks based on carbon nanotube source-gating transistors

## 基于碳纳米管源极门控晶体管的高性能三值逻辑电路和神经网络

Link: https://www.science.org/doi/abs/10.1126/sciadv.adt1909?af=R

**Authors:** Xuehao Zhu, Meiqi Xi, Jianyu Wang, Panpan Zhang, Yi Li, Xiao Luo, Lan Bai, Xingxing Chen, Lian-mao Peng, Yu Cao, Qiliang Li, Xuelei Liang

Science Advances, Volume 11, Issue 2, January 2025. <br />


---
# Beyond nature, nurture, and chance: Individual agency shapes divergent learning biographies and brain connectome

## 超越自然，养育和机会: 个人机构塑造了不同的学习传记和大脑连接组

Link: https://www.science.org/doi/abs/10.1126/sciadv.ads7297?af=R

**Authors:** Warsha Barde, Jonas Renner, Brett Emery, Shahrukh Khanzada, Xin Hu, Alexander Garthe, Annette E. Rünker, Hayder Amin, Gerd Kempermann

Science Advances, Volume 11, Issue 2, January 2025. <br />


---
# Local kernel renormalization as a mechanism for feature learning in overparametrized convolutional neural networks

## 局部核重归一化作为超参数化卷积神经网络特征学习的机制

Link: https://www.nature.com/articles/s41467-024-55229-3

**Authors:** P. Rotondo

<p>Nature Communications, Published online: 10 January 2025; <a href="https://www.nature.com/articles/s41467-024-55229-3">doi:10.1038/s41467-024-55229-3</a></p>Fully connected neural networks in the infinite-width limit often outperform finite-width models, while convolutional networks excel at finite widths. Here, the authors uncover how convolutional networks leverage local, data-dependent kernel renormalization, enabling feature learning to absent in fully connected architectures.


---
# Systematic softening in universal machine learning interatomic potentials

## 通用机器学习中的系统软化原子间势

Link: https://www.nature.com/articles/s41524-024-01500-6

**Authors:** Gerbrand Ceder

<p>npj Computational Materials, Published online: 10 January 2025; <a href="https://www.nature.com/articles/s41524-024-01500-6">doi:10.1038/s41524-024-01500-6</a></p>Systematic softening in universal machine learning interatomic potentials


---
# Discovering novel lead-free solder alloy by multi-objective Bayesian active learning with experimental uncertainty

## 具有实验不确定性的多目标贝叶斯主动学习发现新型无铅焊料合金

Link: https://www.nature.com/articles/s41524-024-01480-7

**Authors:** Tong-Yi Zhang

<p>npj Computational Materials, Published online: 10 January 2025; <a href="https://www.nature.com/articles/s41524-024-01480-7">doi:10.1038/s41524-024-01480-7</a></p>Discovering novel lead-free solder alloy by multi-objective Bayesian active learning with experimental uncertainty


---
# Tree Models Machine Learning to Identify Liquid Metal based Alloy Superconductor

## 树模型机器学习识别液态金属基合金超导体

Link: https://arxiv.org/abs/2501.05164

**Authors:** Chen Hua, Jing Liu

arXiv:2501.05164v1 Announce Type: new 
Abstract: Superconductors, which are crucial for modern advanced technologies due to their zero-resistance properties, are limited by low Tc and the difficulty of accurate prediction. This article made the initial endeavor to apply machine learning to predict the critical temperature (Tc) of liquid metal (LM) alloy superconductors. Leveraging the SuperCon dataset, which includes extensive superconductor property data, we developed a machine learning model to predict Tc. After addressing data issues through preprocessing, we compared multiple models and found that the Extra Trees model outperformed others with an R2 of 0.9519 and an RMSE of 6.2624 K. This model is subsequently used to predict Tc for LM alloys, revealing In0.5Sn0.5 as having the highest Tc at 7.01 K. Furthermore, we extended the prediction to 2,145 alloys binary and 45,670 ternary alloys across 66 metal elements and promising results were achieved. This work demonstrates the advantages of tree-based models in predicting Tc and would help accelerate the discovery of high-performance LM alloy superconductors in the coming time.


---
# Application of pretrained universal machine-learning interatomic potential for physicochemical simulation of liquid electrolytes in Li-ion battery

## 预训练通用机器学习原子间势在锂离子电池液体电解质物理化学模拟中的应用

Link: https://arxiv.org/abs/2501.05211

**Authors:** Suyeon Ju, Jinmu You, Gijin Kim, Yutack Park, Hyungmin An, Seungwu Han

arXiv:2501.05211v1 Announce Type: new 
Abstract: Achieving higher operational voltages, faster charging, and broader temperature ranges for Li-ion batteries necessitates advancements in electrolyte engineering. However, the complexity of optimizing combinations of solvents, salts, and additives has limited the effectiveness of both experimental and computational screening methods for liquid electrolytes. Recently, pretrained universal machine-learning interatomic potentials (MLIPs) have emerged as promising tools for computational exploration of complex chemical spaces with high accuracy and efficiency. In this study, we evaluated the performance of the state-of-the-art equivariant pretrained MLIP, SevenNet-0, in predicting key properties of liquid electrolytes, including solvation behavior, density, and ion transport. To assess its suitability for extensive material screening, we considered a dataset comprising 20 solvents. Although SevenNet-0 was predominantly trained on inorganic compounds, its predictions for the properties of liquid electrolytes showed good agreement with experimental and $\textit{ab initio}$ data. However, systematic errors were identified, particularly in the predicted density of liquid electrolytes. To address this limitation, we fine-tuned SevenNet-0, achieving improved accuracy at a significantly reduced computational cost compared to developing bespoke models. Analysis of the training set suggested that the model achieved its accuracy by generalizing across the chemical space rather than memorizing specific configurations. This work highlights the potential of SevenNet-0 as a powerful tool for future engineering of liquid electrolyte systems.


---
# First-Principles and Machine Learning Insights into the Design of DOTT-Carbon and its Lithium-Ion Storage Capacity

## Dott-carbon的设计及其锂离子存储容量的第一性原理和机器学习见解

Link: https://arxiv.org/abs/2501.05294

**Authors:** Kleuton. A. L. Lima, Ana V. P. Abreu, Alysson M. A. Silva, Luiz A. Ribeiro Jr

arXiv:2501.05294v1 Announce Type: new 
Abstract: Two-dimensional (2D) carbon-based materials are promising candidates for developing more efficient green energy conversion and storage technologies. This study presents a new 2D carbon allotrope, DOTT-Carbon, characterized by its distinctive and multi-ring structure featuring 12-, 8-, 4-, and 3-membered rings of carbon atoms. We explore its structural, mechanical, and lithium-ion storage properties by employing density functional theory and machine learning simulations. Phonon calculations confirm its structural stability and ab initio molecular dynamics simulations demonstrate its thermal resilience at elevated temperatures. The material exhibits anisotropic mechanical properties, with Young's modulus values varying between 280-330 GPa. DOTT-Carbon displays a lithium-ion storage capacity of 446.28 mAh/g, complemented by a low diffusion barrier (0.2-0.9 eV) and a high diffusion coefficient ($ > 1.0 \times 10^{-6}$ cm$^{2}$/s), possibly facilitating efficient lithium-ion transport. The stable open circuit voltage of 0.28 V also indicates its suitability as an anode material.


---
# Discovery of Spin-Crossover Candidates with Equivariant Graph Neural Networks

## 用等变图神经网络发现自旋交叉候选

Link: https://arxiv.org/abs/2501.05341

**Authors:** Angel Albavera-Mata, Pawan Prakash, Jason B. Gibson, Eric Fonseca, Sijin Ren, Xiao-Guang Zhang, Hai-Ping Cheng, Michael Shatruk, S. B. Trickey, Richard G. Hennig

arXiv:2501.05341v1 Announce Type: new 
Abstract: Swift discovery of spin-crossover materials for their potential application in quantum information devices requires techniques which enable efficient identification of suitably bistable candidates. To this end, we screened the Cambridge Structural Database to develop a specialized database of 1,439 materials and computed spin-switching energies from density functional theory for each material. The database was used to train an equivariant graph convolutional neural network to predict the magnitude of the spin-conversion energy. A test mean absolute error was 360 meV. For candidate identification, we equipped the system with a relevance-based classifier. This approach leads to a nearly four-fold improvement in identifying potential spin-crossover systems of interest as compared to conventional high-throughput screening.


---
# Deconvoluting Thermomechanical Effects in X-ray Diffraction Data using Machine Learning

## 使用机器学习对x射线衍射数据中的热机械效应进行反卷积

Link: https://arxiv.org/abs/2408.09447

**Authors:** Rachel E. Lim, Shun-Li Shang, Chihpin Chuang, Thien Q. Phan, Zi-Kui Liu, Darren C. Pagan

arXiv:2408.09447v3 Announce Type: replace 
Abstract: X-ray diffraction is ideal for probing sub-surface state during complex or rapid thermomechanical loading of crystalline materials. However, challenges arise as the size of diffraction volumes increases due to spatial broadening and inability to deconvolute the effects of different lattice deformation mechanisms. Here, we present a novel approach to use combinations of physics-based modeling and machine learning to deconvolve thermal and mechanical elastic strains for diffraction data analysis. The method builds on a previous effort to extract thermal strain distribution information from diffraction data. The new approach is applied to extract the evolution of thermomechanical state during laser melting of an Inconel 625 wall specimen which produces significant residual stress upon cooling. A combination of heat transfer and fluid flow, elasto-plasticity, and X-ray diffraction simulations are used to generate training data for machine-learning (Gaussian Process Regression, GPR) models that map diffracted intensity distributions to underlying thermomechanical strain fields. First-principles density functional theory is used to determine accurate temperature-dependent thermal expansion and elastic stiffness used for elasto-plasticity modeling. The trained GPR models are found to be capable of deconvoluting the effects of thermal and mechanical strains, in addition to providing information about underlying strain distributions, even from complex diffraction patterns with irregularly shaped peaks.


---
# Autoregressive neural quantum states of Fermi Hubbard models

## 费米哈伯德模型的自回归神经量子态

Link: https://arxiv.org/abs/2411.07144

**Authors:** Eduardo Ibarra-Garc\'ia-Padilla, Hannah Lange, Roger G Melko, Richard T Scalettar, Juan Carrasquilla, Annabelle Bohrdt, Ehsan Khatami

arXiv:2411.07144v2 Announce Type: replace 
Abstract: Neural quantum states (NQS) have emerged as a powerful ansatz for variational quantum Monte Carlo studies of strongly-correlated systems. Here, we apply recurrent neural networks (RNNs) and autoregressive transformer neural networks to the Fermi-Hubbard and the (non-Hermitian) Hatano-Nelson-Hubbard models in one and two dimensions. In both cases, we observe that the convergence of the RNN ansatz is challenged when increasing the interaction strength. We present a physically-motivated and easy-to-implement strategy for improving the optimization, namely, by ramping of the model parameters. Furthermore, we investigate the advantages and disadvantages of the autoregressive sampling property of both network architectures. For the Hatano-Nelson-Hubbard model, we identify convergence issues that stem from the autoregressive sampling scheme in combination with the non-Hermitian nature of the model. Our findings provide insights into the challenges of the NQS approach and make the first step towards exploring strongly-correlated electrons using this ansatz.


---
# Intelligent experiments through real-time AI: Fast Data Processing and Autonomous Detector Control for sPHENIX and future EIC detectors

## 通过实时AI进行智能实验: sPHENIX和未来EIC探测器的快速数据处理和自主探测器控制

Link: https://arxiv.org/abs/2501.04845

**Authors:** J. Kvapil (Los Alamos National Laboratory), G. Borca-Tasciuc (Rensselaer Polytechnic Institute), H. Bossi (Massachusetts Institute of Technology), K. Chen (Central China Normal University), Y. Chen (Central China Normal University), Y. Corrales Morales (Massachusetts Institute of Technology), H. Da Costa (Los Alamos National Laboratory), C. Da Silva (Los Alamos National Laboratory), C. Dean (Massachusetts Institute of Technology), J. Durham (Los Alamos National Laboratory), S. Fu (University of North Texas), C. Hao (Georgia Institute of Technology), P. Harris (Massachusetts Institute of Technology), O. Hen (Massachusetts Institute of Technology), H. Jheng (Massachusetts Institute of Technology), Y. Lee (Massachusetts Institute of Technology), P. Li (Georgia Institute of Technology), X. Li (Los Alamos National Laboratory), Y. Lin (Los Alamos National Laboratory), M. X. Liu (Los Alamos National Laboratory), V. Loncar (Massachusetts Institute of Technology), J. P. Mitrevski (Fermilab), A. Olvera (University of North Texas), M. L. Purschke (Brookhaven National Laboratory), J. S. Renck (Los Alamos National Laboratory), G. Roland (Massachusetts Institute of Technology), J. Schambach (Oak Ridge National Laboratory), Z. Shi (Los Alamos National Laboratory), N. Tran (Fermilab), N. Wuerfel (University of Michigan), B. Xu (Georgia Institute of Technology), D. Yu (New Jersey Institute of Technology), H. Zhang (Georgia Institute of Technology)

arXiv:2501.04845v1 Announce Type: new 
Abstract: This R\&amp;D project, initiated by the DOE Nuclear Physics AI-Machine Learning initiative in 2022, leverages AI to address data processing challenges in high-energy nuclear experiments (RHIC, LHC, and future EIC). Our focus is on developing a demonstrator for real-time processing of high-rate data streams from sPHENIX experiment tracking detectors. The limitations of a 15 kHz maximum trigger rate imposed by the calorimeters can be negated by intelligent use of streaming technology in the tracking system. The approach efficiently identifies low momentum rare heavy flavor events in high-rate p+p collisions (3MHz), using Graph Neural Network (GNN) and High Level Synthesis for Machine Learning (hls4ml). Success at sPHENIX promises immediate benefits, minimizing resources and accelerating the heavy-flavor measurements. The approach is transferable to other fields. For the EIC, we develop a DIS-electron tagger using Artificial Intelligence - Machine Learning (AI-ML) algorithms for real-time identification, showcasing the transformative potential of AI and FPGA technologies in high-energy nuclear and particle experiments real-time data processing pipelines.


---
# Using Diffusion Models for Reducing Spatiotemporal Errors of Deep Learning Based Urban Microclimate Predictions at Post-Processing Stage

## 在后处理阶段使用扩散模型减少基于深度学习的城市小气候预测的时空误差

Link: https://arxiv.org/abs/2501.04847

**Authors:** Sepehrdad Tahmasebi, Geng Tian, Shaoxiang Qin, Ahmed Marey, Liangzhu Leon Wang, Saeed Rayegan

arXiv:2501.04847v1 Announce Type: new 
Abstract: Computational fluid dynamics (CFD) is a powerful tool for modeling turbulent flow and is commonly used for urban microclimate simulations. However, traditional CFD methods are computationally intensive, requiring substantial hardware resources for high-fidelity simulations. Deep learning (DL) models are becoming popular as efficient alternatives as they require less computational resources to model complex non-linear interactions in fluid flow simulations. A major drawback of DL models is that they are prone to error accumulation in long-term temporal predictions, often compromising their accuracy and reliability. To address this shortcoming, this study investigates the use of a denoising diffusion probabilistic model (DDPM) as a novel post-processing technique to mitigate error propagation in DL models' sequential predictions. To address this, we employ convolutional autoencoder (CAE) and U-Net architectures to predict airflow dynamics around a cubic structure. The DDPM is then applied to the models' predictions, refining the reconstructed flow fields to better align with high-fidelity statistical results obtained from large-eddy simulations. Results demonstrate that, although deep learning models provide significant computational advantages over traditional numerical solvers, they are susceptible to error accumulation in sequential predictions; however, utilizing DDPM as a post-processing step enhances the accuracy of DL models by up to 65% while maintaining a 3 times speedup compared to traditional numerical solvers. These findings highlight the potential of integrating denoising diffusion probabilistic models as a transformative approach to improving the reliability and accuracy of deep learning-based urban microclimate simulations, paving the way for more efficient and scalable fluid dynamics modeling.


---
# Using Data Science in High School Astronomy

## 在高中天文学中使用数据科学

Link: https://arxiv.org/abs/2501.04856

**Authors:** James Newland (Texas Advanced Computing Center, University of Texas at Austin)

arXiv:2501.04856v1 Announce Type: new 
Abstract: Astronomy datasets can be challenging to use for high school astronomy classes. Data science education pedagogy can be leveraged to create astronomy activities in which students interrogate data, create visuals, and use statistical thinking to construct astronomy knowledge. This session describes how the NASA/IPAC Infrared Science Archive (IRSA) can provide a web-based interface for students to use basic data science techniques in astronomy to build data literacy while learning astronomical concepts. The activities shared will be available for anyone but were designed to be used in astro 101 classes in high school or early college.


---
# A class of enhanced physics-informed neural networks for data-driven solitons and parameters discovery to (2+ 1)-dimensional coupled nonlinear Schrodinger systems with variable coefficients: vector dark and anti-dark one- and two-solitons

## 一类增强的物理信息神经网络，用于数据驱动孤子和参数发现到 (2 1) 维耦合非线性变系数薛定谔系统: 矢量暗和反暗单孤子和双孤子

Link: https://arxiv.org/abs/2501.05011

**Authors:** Hamid Momeni

arXiv:2501.05011v1 Announce Type: new 
Abstract: This paper investigates data-driven solutions and parameter discovery to (2+ 1)-dimensional coupled nonlinear Schrodinger equations with variable coefficients (VC-CNLSEs), which describe transverse effects in optical fiber systems under perturbed dispersion and nonlinearity. By setting different forms of perturbation coefficients, we aim to recover the dark and anti-dark one- and two-soliton structures by employing an enhanced physics-based deep neural network algorithm, namely a physics-informed neural network (PINN). The enhanced PINN algorithm leverages the locally adaptive activation function mechanism to improve convergence speed and accuracy. In the lack of data acquisition, the PINN algorithms will enhance the capability of the neural networks by incorporating physical information into the training phase. We demonstrate that applying PINN algorithms to (2+ 1)-dimensional VC-CNLSEs requires distinct distributions of physical information. To address this, we propose a region-specific weighted loss function with the help of residual-based adaptive refinement strategy. In the meantime, we perform data-driven parameter discovery for the model equation, classified into two categories: constant coefficient discovery and variable coefficient discovery. For the former, we aim to predict the cross-phase modulation constant coefficient under varying noise intensities using enhanced PINN with a single neural network. For the latter, we employ a dual-network strategy to predict the dynamic behavior of the dispersion and non-linearity perturbation functions. Our study demonstrates that the proposed framework holds significant potential for studying high-dimensional and complex soliton dynamics in optical fiber systems.


---
# Simultaneous emulation and downscaling with physically-consistent deep learning-based regional ocean emulators

## 使用基于物理一致的深度学习的区域海洋仿真器进行同步仿真和缩减

Link: https://arxiv.org/abs/2501.05058

**Authors:** Leonard Lupin-Jimenez, Moein Darman, Subhashis Hazarika, Tianning Wu, Michael Gray, Ruyoing He, Anthony Wong, Ashesh Chattopadhyay

arXiv:2501.05058v1 Announce Type: new 
Abstract: Building on top of the success in AI-based atmospheric emulation, we propose an AI-based ocean emulation and downscaling framework focusing on the high-resolution regional ocean over Gulf of Mexico. Regional ocean emulation presents unique challenges owing to the complex bathymetry and lateral boundary conditions as well as from fundamental biases in deep learning-based frameworks, such as instability and hallucinations. In this paper, we develop a deep learning-based framework to autoregressively integrate ocean-surface variables over the Gulf of Mexico at $8$ Km spatial resolution without unphysical drifts over decadal time scales and simulataneously downscale and bias-correct it to $4$ Km resolution using a physics-constrained generative model. The framework shows both short-term skills as well as accurate long-term statistics in terms of mean and variability.


---
# Constrained Optimization of Charged Particle Tracking with Multi-Agent Reinforcement Learning

## 基于多智能体强化学习的带电粒子跟踪约束优化

Link: https://arxiv.org/abs/2501.05113

**Authors:** Tobias Kortus (for the Bergen pCT Collaboration), Ralf Keidel (for the Bergen pCT Collaboration), Nicolas R. Gauger (for the Bergen pCT Collaboration), Jan Kieseler (for the Bergen pCT Collaboration)

arXiv:2501.05113v1 Announce Type: new 
Abstract: Reinforcement learning demonstrated immense success in modelling complex physics-driven systems, providing end-to-end trainable solutions by interacting with a simulated or real environment, maximizing a scalar reward signal. In this work, we propose, building upon previous work, a multi-agent reinforcement learning approach with assignment constraints for reconstructing particle tracks in pixelated particle detectors. Our approach optimizes collaboratively a parametrized policy, functioning as a heuristic to a multidimensional assignment problem, by jointly minimizing the total amount of particle scattering over the reconstructed tracks in a readout frame. To satisfy constraints, guaranteeing a unique assignment of particle hits, we propose a safety layer solving a linear assignment problem for every joint action. Further, to enforce cost margins, increasing the distance of the local policies predictions to the decision boundaries of the optimizer mappings, we recommend the use of an additional component in the blackbox gradient estimation, forcing the policy to solutions with lower total assignment costs. We empirically show on simulated data, generated for a particle detector developed for proton imaging, the effectiveness of our approach, compared to multiple single- and multi-agent baselines. We further demonstrate the effectiveness of constraints with cost margins for both optimization and generalization, introduced by wider regions with high reconstruction performance as well as reduced predictive instabilities. Our results form the basis for further developments in RL-based tracking, offering both enhanced performance with constrained policies and greater flexibility in optimizing tracking algorithms through the option for individual and team rewards.


---
# Principles and Metrics of Extreme Learning Machines Using a Highly Nonlinear Fiber

## 使用高度非线性光纤的极限学习机的原理和指标

Link: https://arxiv.org/abs/2501.05233

**Authors:** Mathilde Hary, Daniel Brunner, Lev Leybov, Piotr Ryczkowski, John M. Dudley, Go\"ery Genty

arXiv:2501.05233v1 Announce Type: new 
Abstract: Optical computing offers potential for ultra high-speed and low latency computation by leveraging the intrinsic properties of light. Here, we explore the use of highly nonlinear optical fibers (HNLFs) as platforms for optical computing based on the concept of Extreme Learning Machines. Task-independent evaluations are introduced to the field for the first time and focus on the fundamental metrics of effective dimensionality and consistency, which we experimentally characterize for different nonlinear and dispersive conditions. We show that input power and fiber characteristics significantly influence the dimensionality of the computational system, with longer fibers and higher dispersion producing up to 100 principal components (PCs) at input power levels of 30 mW, where the PC correspond to the linearly independent dimensions of the system. The spectral distribution of the PC's eigenvectors reveals that the high-dimensional dynamics facilitating computing through dimensionality expansion are located within 40~nm of the pump wavelength at 1560~nm, providing general insight for computing with nonlinear Schr\"odinger equation systems. Task-dependent results demonstrate the effectiveness of HNLFs in classifying MNIST dataset images. Using input data compression through PC analysis, we inject MNIST images of various input dimensionality into the system and study the impact of input power upon classification accuracy. At optimized power levels we achieve a classification test accuracy of 88\%, significantly surpassing the baseline of 83.7\% from linear systems. Noteworthy, we find that best performance is not obtained at maximal input power, i.e. maximal system dimensionality, but at more than one order of magnitude lower. The same is confirmed regarding the MNIST image's compression, where accuracy is substantially improved when strongly compressing the image to less than 50 PCs.


---
# Providing Machine Learning Potentials with High Quality Uncertainty Estimates

## 提供具有高质量不确定性估计的机器学习潜力

Link: https://arxiv.org/abs/2501.05250

**Authors:** Zeynep Sumer, James L. McDonagh, Clyde Fare, Ravikanth Tadikonda, Viktor Zolyomi, David Bray, Edward Pyzer-Knapp

arXiv:2501.05250v1 Announce Type: new 
Abstract: Computational chemistry has come a long way over the course of several decades, enabling subatomic level calculations particularly with the development of Density Functional Theory (DFT). Recently, machine-learned potentials (MLP) have provided a way to overcome the prevalent time and length scale constraints in such calculations. Unfortunately, these models utilise complex and high dimensional representations, making it challenging for users to intuit performance from chemical structure, which has motivated the development of methods for uncertainty quantification. One of the most common methods is to introduce an ensemble of models and employ an averaging approach to determine the uncertainty. In this work, we introduced Bayesian Neural Networks (BNNs) for uncertainty aware energy evaluation as a more principled and resource efficient method to achieve this goal. The richness of our uncertainty quantification enables a new type of hybrid workflow where calculations can be offloaded to a MLP in a principled manner.


---
# Data-driven methods to discover stable linear models of the helicity injectors on HIT-SIU

## 数据驱动方法发现hit-siu上螺旋度注入器的稳定线性模型

Link: https://arxiv.org/abs/2501.05405

**Authors:** Zachary L. Daniel, Alan A. Kaptanoglu, Christopher J. Hansen, Kyle D. Morgan, Steven L. Brunton, J. Nathan Kutz

arXiv:2501.05405v1 Announce Type: new 
Abstract: Accurate and efficient circuit models are necessary to control the power electronic circuits found on plasma physics experiments. Tuning and controlling the behavior of these circuits is inextricably linked to plasma performance. Linear models are greatly preferred for control applications due to their well-established performance guarantees, but they typically fail to capture nonlinear dynamics and changes in experimental parameters. Data-driven system identification can help mitigate these shortcomings by learning interpretable and accurate reduced-order models of a complex system, in this case the injector circuits of the Helicity Injected Torus - Steady Inductive Upgrade (HIT-SIU) experiment. Specifically, the Bagging Optimized Dynamic Mode Decomposition (BOP-DMD), is leveraged to learn stable, reduced order models of the interaction between the spheromak plasma formed in the confinement volume, and the injector circuits of the device. BOP-DMD is trained and evaluated on an analytic model of the vacuum dynamics of the injector circuits of HIT-SIU, as well as an analytic linear reduced-order model for the injector dynamics when a plasma is present. BOP-DMD is then fit on experimental data, both on shots with and without a plasma in the confinement volume. In doing so, we demonstrate the capability of data-driven methods to produce stable, linear models for control and uncertainty quantification in plasma experiments.


---
# Generative Style Transfer for MRI Image Segmentation: A Case of Glioma Segmentation in Sub-Saharan Africa

## 用于MRI图像分割的生成式转换: 以撒哈拉以南非洲的神经胶质瘤分割为例

Link: https://arxiv.org/abs/2501.04734

**Authors:** Rancy Chepchirchir, Jill Sunday, Raymond Confidence, Dong Zhang, Talha Chaudhry, Udunna C. Anazodo, Kendi Muchungi, Yujing Zou

arXiv:2501.04734v1 Announce Type: cross 
Abstract: In Sub-Saharan Africa (SSA), the utilization of lower-quality Magnetic Resonance Imaging (MRI) technology raises questions about the applicability of machine learning methods for clinical tasks. This study aims to provide a robust deep learning-based brain tumor segmentation (BraTS) method tailored for the SSA population using a threefold approach. Firstly, the impact of domain shift from the SSA training data on model efficacy was examined, revealing no significant effect. Secondly, a comparative analysis of 3D and 2D full-resolution models using the nnU-Net framework indicates similar performance of both the models trained for 300 epochs achieving a five-fold cross-validation score of 0.93. Lastly, addressing the performance gap observed in SSA validation as opposed to the relatively larger BraTS glioma (GLI) validation set, two strategies are proposed: fine-tuning SSA cases using the GLI+SSA best-pretrained 2D fullres model at 300 epochs, and introducing a novel neural style transfer-based data augmentation technique for the SSA cases. This investigation underscores the potential of enhancing brain tumor prediction within SSA's unique healthcare landscape.


---
# Development of an Adaptive Sliding Mode Controller using Neural Networks for Trajectory Tracking of a Cylindrical Manipulator

## 使用神经网络开发用于圆柱机械手轨迹跟踪的自适应滑模控制器

Link: https://arxiv.org/abs/2501.04754

**Authors:** TieuNien Le, VanCuong Pham, NgocSon Vu

arXiv:2501.04754v1 Announce Type: cross 
Abstract: Cylindrical manipulators are extensively used in industrial automation, especially in emerging technologies like 3D printing, which represents a significant future trend. However, controlling the trajectory of nonlinear models with system uncertainties remains a critical challenge, often leading to reduced accuracy and reliability. To address this, the study develops an Adaptive Sliding Mode Controller (ASMC) integrated with Neural Networks (NNs) to improve trajectory tracking for cylindrical manipulators. The ASMC leverages the robustness of sliding mode control and the adaptability of neural networks to handle uncertainties and dynamic variations effectively. Simulation results validate that the proposed ASMC-NN achieves high trajectory tracking accuracy, fast response time, and enhanced reliability, making it a promising solution for applications in 3D printing and beyond.


---
# EquiBoost: An Equivariant Boosting Approach to Molecular Conformation Generation

## Equboost: 分子构象生成的等变增强方法

Link: https://arxiv.org/abs/2501.05109

**Authors:** Yixuan Yang, Xingyu Fang, Zhaowen Cheng, Pengju Yan, Xiaolin Li

arXiv:2501.05109v1 Announce Type: cross 
Abstract: Molecular conformation generation plays key roles in computational drug design. Recently developed deep learning methods, particularly diffusion models have reached competitive performance over traditional cheminformatical approaches. However, these methods are often time-consuming or require extra support from traditional methods. We propose EquiBoost, a boosting model that stacks several equivariant graph transformers as weak learners, to iteratively refine 3D conformations of molecules. Without relying on diffusion techniques, EquiBoost balances accuracy and efficiency more effectively than diffusion-based methods. Notably, compared to the previous state-of-the-art diffusion method, EquiBoost improves generation quality and preserves diversity, achieving considerably better precision of Average Minimum RMSD (AMR) on the GEOM datasets. This work rejuvenates boosting and sheds light on its potential to be a robust alternative to diffusion models in certain scenarios.


---
# Holographic Metasurfaces Enabling Wave Computing for 6G: Status Overview, Challenges, and Future Research Trends

## 支持6g波计算的全息元表面: 现状概述、挑战和未来研究趋势

Link: https://arxiv.org/abs/2501.05173

**Authors:** Zahra Rahimian Omam, Hamidreza Taghvaee, Ali Araghi, Maria Garcia-Fernandez, Guillermo Alvarez-Narciandi, George C. Alexandropoulos, Okan Yurduseven, Mohsen Khalily

arXiv:2501.05173v1 Announce Type: cross 
Abstract: Recent advancements in wave computing using metasurfaces are poised to transform wireless communications by enabling high-speed, energy-efficient, and highly parallelized signal processing. These capabilities are essential to meet the ultra-high data rates of up to 1 terabit per second and minimal latency as low as 1 millisecond required by next-generation wireless networks. Diverging from traditional digital processing, wave computing adopts continuous analog signals to foster innovative functions such as over-the-air computation, integrated sensing and communications, computational electromagnetic imaging, and physical-layer security. This article explores the potential of reconfigurable multi-functional metasurfaces in wave computing, emphasizing their pivotal role in facilitating seamless communications and addressing the escalating computational demands for sixth generation (6G) networks. As artificial intelligence has become one of the most prominent and rapidly advancing fields of research over the last decade, we also introduce a wave-domain-based machine learning approach aimed at achieving power-efficient, fast training and computation. Future research directions are discussed, underscoring how metasurface-based systems can merge computation with communication to innovate components of 6G networks, thus creating smarter, faster, and more adaptable wireless infrastructures.


---
# Local predictors of explosive synchronization with ordinal methods

## 使用序数方法进行爆炸同步的局部预测器

Link: https://arxiv.org/abs/2501.05202

**Authors:** I. Leyva, Juan A. Almendral, Christophe Letellier, I. Sendi\~na-Nadal

arXiv:2501.05202v1 Announce Type: cross 
Abstract: We propose to use the ordinal pattern transition (OPT) entropy measured at sentinel central nodes as a potential predictor of explosive transitions to synchronization in networks of various dynamical systems with increasing complexity. Our results demonstrate that the OPT entropic measure surpasses traditional early warning signals (EWS) measures and could be valuable to the tools available for predicting critical transitions. In particular, we investigate networks of diffusively coupled phase oscillators and chaotic R\"ossler systems. As maps, we consider a neural network of Chialvo maps coupled in star and scale-free configurations. Furthermore, we apply this measure to time series data obtained from a network of electronic circuits operating in the chaotic regime.


---
# Exploring near-optimal energy systems with stakeholders: a novel approach for participatory modelling

## 与利益相关者探索接近最佳的能源系统: 参与式建模的新方法

Link: https://arxiv.org/abs/2501.05280

**Authors:** Oskar V{\aa}ger\"o, Koen van Greevenbroek, Aleksander Grochowicz, Maximilian Roithner

arXiv:2501.05280v1 Announce Type: cross 
Abstract: Involving people in energy systems planning can increase the legitimacy and socio-political feasibility of energy transitions. Participatory research in energy modelling offers the opportunity to engage with stakeholders in a comprehensive way, but is limited by how results can be generated and presented without imposing assumptions and discrete scenarios on the participants. To this end, we present a methodology and a framework, based on near-optimal modelling results, that can incorporate stakeholders in a holistic and engaging way. We confront stakeholders with a continuum of modelling-based energy system designs via an interactive interface allowing them to choose essentially any combination of components that meet the system requirements. Together with information on the implications of different technologies, it is possible to assess how participants prioritise different aspects in energy systems planning while also facilitating learning in an engaging and stimulating way. We showcase the methodology for the remote Arctic settlement of Longyearbyen and illustrate how participants deviate consistently from the cost optimum. At the same time, they manage to balance different priorities such as emissions, costs, and system vulnerability leading to a better understanding of the complexity and intertwined nature of decisions.


---
# Differences in the attitudes and beliefs about science of students in the physics-mathematics and life sciences areas and their impact on teaching

## 物理数学和生命科学领域学生对科学的态度和信念的差异及其对教学的影响

Link: https://arxiv.org/abs/2202.11680

**Authors:** Alvaro Suarez, Daniel Baccino, Martin Monteiro, Arturo C. Marti

arXiv:2202.11680v4 Announce Type: replace 
Abstract: For this study, we compared the attitudes and beliefs about science of physical science (physics and mathematics) and life science (biochemistry and biology) students at the beginning of their university degrees using the CLASS (Colorado Learning Attitudes about Science Survey) tool. It is worth noting that both groups of students received similar physics courses during their high-school education. Through a detailed analysis of the different categories of the test, we examined the differences in performance in each of the areas that make up the questionnaire. Among other aspects, we found that a considerable percentage of life science students (higher than that of physical science students) adopted a novice type of behavior in problem solving. Finally, we discussed the possible causes of the differences found and their implications for teaching.


---
# Exploiting the geometry of heterogeneous networks: A case study of the Indian stock market

## 利用异构网络的几何形状: 以印度股票市场为例

Link: https://arxiv.org/abs/2404.04710

**Authors:** Pawanesh Pawanesh, Charu Sharma, Niteesh Sahni

arXiv:2404.04710v3 Announce Type: replace 
Abstract: In this study, we model the Indian stock market as heterogenous scale free network, which is then embedded in a two dimensional hyperbolic space through a machine learning based technique called as coalescent embedding. This allows us to apply the hyperbolic kmeans algorithm on the Poincare disc and the clusters so obtained resemble the original network communities more closely than the clusters obtained via Euclidean kmeans on the basis of well-known measures normalised mutual information and adjusted mutual information. Through this, we are able to clearly distinguish between periods of market stability and volatility by applying non-parametric statistical tests with a significance level of 0.05 to geometric measures namely hyperbolic distance and hyperbolic shortest path distance. After that, we are able to spot significant market change early by leveraging the Bollinger Band analysis on the time series of modularity in the embedded networks of each window. Finally, the radial distance and the Equidistance Angular coordinates help in visualizing the embedded network in the Poincare disc and it is seen that specific market sectors cluster together.


---
# Building a human-like observer using deep learning in an extended Wigner's friend experiment

## 在扩展的Wigner&#39;s friend实验中使用深度学习构建类似人类的观察者

Link: https://arxiv.org/abs/2409.04690

**Authors:** Jinjun Zeng, Xiao Zhang

arXiv:2409.04690v2 Announce Type: replace 
Abstract: There has been a longstanding demand for artificial intelligence with human-level cognitive sophistication to address loopholes in Bell-type experiments. In this study, we propose a novel experimental framework that integrates advanced deep learning techniques, employing neural network-based artificial intelligence in an extended Wigner's friend experiment. We demonstrate the framework through simulations and introduce three new analytical metrics-morphing polygons, averaged Shannon entropy, and probability density maps-to evaluate the results. These results can be used to determine whether our artificial intelligence qualifies as a bona fide observer and whether superposition applies to macroscopic systems, including observers.


---
# Deep Overlapping Community Search via Subspace Embedding

## 基于子空间嵌入的深度重叠社区搜索

Link: https://arxiv.org/abs/2404.14692

**Authors:** Qing Sima, Jianke Yu, Xiaoyang Wang, Wenjie Zhang, Ying Zhang, Xuemin Lin

arXiv:2404.14692v3 Announce Type: replace-cross 
Abstract: Overlapping Community Search (OCS) identifies nodes that interact with multiple communities based on a specified query. Existing community search approaches fall into two categories: algorithm-based models and Machine Learning-based (ML) models. Despite the long-standing focus on this topic within the database domain, current solutions face two major limitations: 1) Both approaches fail to address personalized user requirements in OCS, consistently returning the same set of nodes for a given query regardless of user differences. 2) Existing ML-based CS models suffer from severe training efficiency issues. In this paper, we formally redefine the problem of OCS. By analyzing the gaps in both types of approaches, we then propose a general solution for OCS named Sparse Subspace Filter (SSF), which can extend any ML-based CS model to enable personalized search in overlapping structures. To overcome the efficiency issue in the current models, we introduce Simplified Multi-hop Attention Networks (SMN), a lightweight yet effective community search model with larger receptive fields. To the best of our knowledge, this is the first ML-based study of overlapping community search. Extensive experiments validate the superior performance of SMN within the SSF pipeline, achieving a 13.73% improvement in F1-Score and up to 3 orders of magnitude acceleration in model efficiency compared to state-of-the-art approaches.


---
# Deconvoluting Thermomechanical Effects in X-ray Diffraction Data using Machine Learning

## 使用机器学习对x射线衍射数据中的热机械效应进行反卷积

Link: https://arxiv.org/abs/2408.09447

**Authors:** Rachel E. Lim, Shun-Li Shang, Chihpin Chuang, Thien Q. Phan, Zi-Kui Liu, Darren C. Pagan

arXiv:2408.09447v3 Announce Type: replace-cross 
Abstract: X-ray diffraction is ideal for probing sub-surface state during complex or rapid thermomechanical loading of crystalline materials. However, challenges arise as the size of diffraction volumes increases due to spatial broadening and inability to deconvolute the effects of different lattice deformation mechanisms. Here, we present a novel approach to use combinations of physics-based modeling and machine learning to deconvolve thermal and mechanical elastic strains for diffraction data analysis. The method builds on a previous effort to extract thermal strain distribution information from diffraction data. The new approach is applied to extract the evolution of thermomechanical state during laser melting of an Inconel 625 wall specimen which produces significant residual stress upon cooling. A combination of heat transfer and fluid flow, elasto-plasticity, and X-ray diffraction simulations are used to generate training data for machine-learning (Gaussian Process Regression, GPR) models that map diffracted intensity distributions to underlying thermomechanical strain fields. First-principles density functional theory is used to determine accurate temperature-dependent thermal expansion and elastic stiffness used for elasto-plasticity modeling. The trained GPR models are found to be capable of deconvoluting the effects of thermal and mechanical strains, in addition to providing information about underlying strain distributions, even from complex diffraction patterns with irregularly shaped peaks.


---
# Evaluation of uncertainty estimations for Gaussian process regression based machine learning interatomic potentials

## 基于高斯过程回归的机器学习原子间势的不确定性估计评估

Link: https://arxiv.org/abs/2410.20398

**Authors:** Matthias Holzenkamp, Dongyu Lyu, Ulrich Kleinekath\"ofer, Peter Zaspel

arXiv:2410.20398v2 Announce Type: replace-cross 
Abstract: Uncertainty estimations for machine learning interatomic potentials (MLIPs) are crucial for quantifying model error and identifying informative training samples in active learning strategies. In this study, we evaluate uncertainty estimations of Gaussian process regression (GPR)-based MLIPs, including the predictive GPR standard deviation and ensemble-based uncertainties. We do this in terms of calibration and in terms of impact on model performance in an active learning scheme. We consider GPR models with Coulomb and Smooth Overlap of Atomic Positions (SOAP) representations as inputs to predict potential energy surfaces and excitation energies of molecules. Regarding calibration, we find that ensemble-based uncertainty estimations show already poor global calibration (e.g., averaged over the whole test set). In contrast, the GPR standard deviation shows good global calibration, but when grouping predictions by their uncertainty, we observe a systematical bias for predictions with high uncertainty. Although an increasing uncertainty correlates with an increasing bias, the bias is not captured quantitatively by the uncertainty. Therefore, the GPR standard deviation can be useful to identify predictions with a high bias and error but, without further knowledge, should not be interpreted as a quantitative measure for a potential error range. Selecting the samples with the highest GPR standard deviation from a fixed configuration space leads to a model that overemphasizes the borders of the configuration space represented in the fixed dataset. This may result in worse performance in more densely sampled areas but better generalization for extrapolation tasks.


---
# Trading Devil RL: Backdoor attack via Stock market, Bayesian Optimization and Reinforcement Learning

## 交易魔鬼RL: 通过股票市场，贝叶斯优化和强化学习进行后门攻击

Link: https://arxiv.org/abs/2412.17908

**Authors:** Orson Mengara

arXiv:2412.17908v2 Announce Type: replace-cross 
Abstract: With the rapid development of generative artificial intelligence, particularly large language models, a number of sub-fields of deep learning have made significant progress and are now very useful in everyday applications. For example, well-known financial institutions simulate a wide range of scenarios for various models created by their research teams using reinforcement learning, both before production and after regular operations. In this work, we propose a backdoor attack that focuses solely on data poisoning. This particular backdoor attack is classified as an attack without prior consideration or trigger, and we name it FinanceLLMsBackRL. Our aim is to examine the potential effects of large language models that use reinforcement learning systems for text production or speech recognition, finance, physics, or the ecosystem of contemporary artificial intelligence models.


---
# A Machine Learning Workflow to Enhance Microfluidic Development of Nanomedicines

## 用于增强纳米医学微流控开发的机器学习工作流程

Link: https://dx.doi.org/10.26434/chemrxiv-2025-2lb14?rft_dat=source%3Ddrss

**Authors:** Paolo, Decuzzi

Artificial intelligence (AI) is being implemented in almost every facet of modern-day life, and machine learning, a subfield of AI, has the potential to greatly streamline the process of developing various nanomedicines using microfluidic fabrication techniques. The availability of open-source machine learning frameworks makes these powerful tools accessible to scientists, facilitating the integration of wet-bench activities with computational analysis. Here, we present a machine learning workflow aimed at optimizing the microfluidic formulation development of nanomedicines. A database of almost 200 unique nanomedicine formulations with over 550 total measurements was curated by producing liposomes, lipid nanoparticles, and PLGA nanoparticles using a benchtop microfluidic system. Microfluidic and materials input features, including the total flow rate, aqueous:organic flow rate ratio, and reagent concentrations, were systematically varied, and the resulting particles were characterized for their hydrodynamic diameter (dH), polydispersity index (PdI), and encapsulation efficiency (EE) for a model therapeutic agent, curcumin (CURC). These data were used to train, test, and validate 13 different machine learning models with the task of returning the most accurate prediction of the nanomedicine attributes – dH, PdI, EE.  The most accurate machine learning models, based on random forest regression, were implemented to provide the optimal formulation to yield particles with user-specified attributes. Finally, this system, dubbed MicrofluidicML, was compared against generative large language models as represented by the Open AI ChatGPT and Google’s Gemini platforms. The application of machine learning in the field of nanomedicine is inevitable, and MicrofluidicML represents a step towards implementing a machine learning framework towards accelerating formulation development.


---
# Data Efficient Learning of Molecular Slow Modes from Nonequilibrium Metadynamics

## 从非平衡元动力学中有效学习分子慢模式的数据

Link: https://dx.doi.org/10.26434/chemrxiv-2025-vswkj?rft_dat=source%3Ddrss

**Authors:** Jack, Hanni

Enhanced sampling simulations help overcome free energy barriers and explore molecular conformational space by applying external bias potential along suitable collective variables (CVs). However, identifying optimal CVs that align with the slow modes of complex molecular systems with many coupled degrees of freedom can be a significant challenge. Deep time-lagged independent component analysis (Deep-TICA) addresses this issue by employing an artificial neural network that generates non-linear combinations of molecular descriptors to learn the slowest degrees of freedom. Training Deep-TICA CVs, however, typically requires long equilibrium simulations that can sample multiple recrossing events across various metastable conformations of the molecule. This requirement can often be prohibitively expensive, thereby limiting its widespread application. In this study, we present an algorithm that enables the training of Deep-TICA CVs using a limited amount of trajectory data obtained from short non-equilibrium metadynamics simulations that only sample one forward transition from the initial to the final state. We achieve this by utilizing the variational Koopman algorithm, which reweights short off-equilibrium trajectories to reflect the equilibrium probability densities. We demonstrate that enhanced sampling simulations conducted along the Koopman reweighted Deep-TICA CV can accurately and efficiently converge the free energy surface for systems such as the Muller-Brown Potential, Alanine Dipeptide, and the chignolin mini-protein. Our approach, therefore, addresses the key challenge of inferring slow modes from limited trajectory data, making it more feasible to use deep learning CVs to study molecular processes of practical relevance.


---
# Which modern AI methods provide accurate predictions of toxicological endpoints? Analysis of Tox24 challenge results.

## 哪些现代AI方法可以准确预测毒理学终点？Tox24挑战结果的分析。

Link: https://dx.doi.org/10.26434/chemrxiv-2025-7k7x3?rft_dat=source%3Ddrss

**Authors:** Igor V., Tetko

The Tox24 challenge was designed to evaluate the progress that has been made in computational method development for the prediction of in vitro activity since the Tox21 challenge. In this challenge, participants were tasked with developing models to predict chemical binding to transthyretin (TTR), a serum binding protein, based on chemical structure. The analyzed dataset included chemicals that were screened in a competitive binding assay designed to measure the reduction in fluorescence due to displacement of 8-anilino-1-naphthalenesulfonic acid ammonium salt (ANSA) from TTR. The data were randomly split into a training set of 1012 compounds, a leaderboard set of 200, and a blind set of 300. This article provides an overview of the Tox24 Challenge and some of the models developed by the participating teams. Some of the approaches taken by winning teams included use of mixtures, enumerating tautomers, data cleaning. Many of the teams used consensus models. Overall, there has been significant progress in the development of machine learning tools since the Tox21 Challenge.


---
# Modeling Boltzmann weighted structural ensembles of proteins using AI based methods

## 使用基于AI的方法对蛋白质的玻尔兹曼加权结构集合进行建模

Link: https://dx.doi.org/10.26434/chemrxiv-2024-6f9h6-v3?rft_dat=source%3Ddrss

**Authors:** Pratyush, Tiwary

This review highlights recent advances in AI-driven methods for generating Boltzmann-weighted structural ensembles, which are crucial for understanding biomolecular dynamics and drug discovery. With the rise of deep learning models like AlphaFold2, there has been a shift toward more accurate and efficient sampling of structural ensembles. The review discusses the integration of AI with traditional molecular dynamics techniques as well as experiments, the challenges of conformational sampling, and future directions for AI-driven research in structural biology, particularly in drug discovery and protein dynamics.


---
# Metaproteomics beyond databases: addressing the challenges and potentials of de novo sequencing

## 超越数据库的元蛋白质组学: 应对从头测序的挑战和潜力

Link: https://dx.doi.org/10.26434/chemrxiv-2024-4v6q0-v2?rft_dat=source%3Ddrss

**Authors:** Sam, van Puyenbroeck

Metaproteomics enables the large-scale characterization of microbial community proteins, offering crucial insights into their taxonomic composition, functional activities, and interactions within their environments. By directly analyzing proteins, metaproteomics offers insights on community phenotypes and the roles individual members play in diverse ecosystems. While database-dependent search engines are commonly used for peptide identification, they rely on pre-existing protein databases, which can be limiting for complex, poorly characterized microbiomes. De novo sequencing presents a promising alternative, which derives peptide sequences directly from mass spectra without requiring a database. Over time, this approach has evolved from manual annotation to advanced graph-based, tag-based, and deep learning-based methods, significantly improving the accuracy of peptide identification. This Viewpoint explores the evolution, advantages, limitations, and future opportunities of de novo sequencing in metaproteomics. We highlight recent technological advancements that have improved its potential for detecting unsequenced species and for providing deeper functional insights into microbial communities.


---
# Scale matters: simulation of nanoscopic dendrite initiation in the lithium solid electrolyte interphase using a machine learning potential

## 尺度问题: 使用机器学习潜力模拟锂固体电解质界面中纳米枝晶的引发

Link: https://dx.doi.org/10.26434/chemrxiv-2024-86s6m-v2?rft_dat=source%3Ddrss

**Authors:** Svetha, Venkatesh

Although lithium solid state electrolytes promise to mitigate the chemical instabilities of liquid electrolytes in today's mainstream rechargeable batteries, solid state electrolytes still suffer from dendrite formation which leads to battery degradation and short circuiting. Dendrite initiation and propagation in specific solid state electrolyte materials has been explained, at a microscopic scale, as emerging from the lithium-filling of pores within the solid state electrolytes via microcracks. At the atomistic scale, the thermodynamic instability of many solid state electrolyte materials can explain their susceptibility to crystal decomposition upon contact with the lithium anode. However, for a more complete picture of the dendrite formation mechanisms, an understanding of the dendrite initiation mechanism at the intermediate nanoscopic scale is required. This work applies a machine learning potential (DIEP) for simulating six different solid state electrolyte-lithium interfaces at 300 K and 1000 K, with model sizes ranging from 24k to 36k atoms, for durations exceeding 20 ps. Our simulations show that the lithium dendrite initiation process can have an underpinning nanoscopic mechanism, in which the crystal decomposition by direct lithium interaction leads to the clustering of lithium. The simulations also suggest a possible mechanism for the creation of voids within the solid-electrolyte interphase, which have been observed in the Li$|$Li$_6$PS$_5$Cl$|$Li interface.


---
# Detection And Grading of Rust Disease Severities from Wheat Images Using Deep Learning Techniques

## 使用深度学习技术从小麦图像中检测和分级锈病严重程度

Link: https://www.researchsquare.com/article/rs-5796873/latest

Wheat production, a cornerstone of food security in Ethiopia, is heavily impacted by stripe rust disease, which leads to significant economic losses. Traditional methods for detecting and classifying disease severity are labor-intensive, error-prone, and costly. This study introduces a novel convolutional neural network (CNN)-based model, WRNet, designed for the detection and severity classification of wheat yellow rust disease, along with treatment recommendations. Utilizing 20,000 annotated images collected from Ethiopia, the model applies advanced preprocessing techniques such as noise removal and segmentation using bilateral filtering and k-means algorithms. The WRNet model achieved superior performance with 99.11% training accuracy, 99.04% validation accuracy, and 99% testing accuracy, surpassing pre-trained models such as InceptionV3, InceptionResNetV2, and MobileNetV2. Additionally, the system provides fungicide dosage recommendations tailored to severity levels, ensuring effective disease management. A user-friendly prototype interface developed using Flask enables domain experts to classify disease severity and receive treatment recommendations, offering a scalable solution for precision agriculture in Ethiopia and beyond.


---
# Enhancing Practical Design Skills Using AI-Powered Graphic Design Platforms: A Pedagogical Framework for Beginner Learners.

## 使用AI驱动的图形设计平台增强实用设计技能: 面向初学者的教学框架。

Link: https://www.researchsquare.com/article/rs-5791462/latest

The integration of artificial intelligence (AI) tools into graphic design education has gained attention as a means to simplify skill acquisition for beginners. Traditional graphic design tools often present steep learning curves, making it difficult for novice learners to acquire practical skills without extensive technical expertise. This paper proposes the IIH-AILP Model, a structured pedagogical framework designed to leverage AI-powered platforms such as Canva and Adobe Firefly to improve accessibility, inclusivity, and efficiency in graphic design education. The methodology employs a 12-week intervention with a mix of sequential and integrated components, including pre- and post-assessments, modular learning, skill progression, gamified engagement, and comparative evaluations. Participants&amp;rsquo; design abilities were assessed across creativity, task completion time, and learning curve improvements using carefully designed evaluation metrics. The results demonstrate that the IIH-AILP model significantly reduces the learning curve, enhances creativity, and improves task efficiency, confirming the potential of AI-powered graphic design platforms to streamline education for beginners with little to no technical expertise.


---
# Rice Bran Extract attenuates cognitive impairment by enhancing pancreatic &beta;-cell insulin secretion in STZ-induced diabetic rats targeting the PPAR&gamma;/PDX1 pathway

## 米糠提取物通过增强STZ诱导的糖尿病大鼠胰腺 β 细胞胰岛素分泌来减轻认知障碍，靶向PPAR & γ;/PDX1通路

Link: https://www.researchsquare.com/article/rs-5702421/latest

Type I diabetes (T1D), also known as juvenile diabetes, is an autoimmune disease that causes gradual destruction of pancreatic cells and leads to intellectual disability, neuropathy, cognitive impairment, and impaired learning ability in children. Despite standard treatment with synthetic human insulin, T1D patients can maintain up to 40% of their insulin-producing islets. PPAR&gamma; receptor activation research that aims to restore &beta;-cell biology could help reverse the loss of pancreatic mass that comes with getting older and improve &beta;-cell function. Egyptian RB ethanol extract (RBE), previously reported with PPAR&gamma; agonist activity, showed an increase in insulin secretion both in vivo and in INS-1 cells. The exact antidiabetic RBE mechanism is still unclear. The present study aims to investigate the molecular RBE mechanism in glucose-stimulating insulin secretion and restoration of &beta; cell function. A diabetic rat streptozotocin (STZ) model was used; five groups were designed. The STZ-diabetic rats were treated with RBE daily for 21 days compared to an insulin-treated group. Biochemical parameters and quantitative RT-PCR of &beta;-cell genes related to the PPAR/PDX1 signaling pathway were performed, and the influence on cognitive ability was confirmed by behavioral testing (Y-maze and NOR) and histological examination. The RBE-treated group reversed blood glucose, Glut2, Ca2+, and insulin levels in diabetic rats, with pancreatic insulin levels significantly increasing compared to the insulin group. With the exception of PDX1, RBE boosted PPAR&gamma;, SERCA, and PrKC gene expression. RBE also restored cognitive functions. This study suggests that RBE may enhance memory and cognition by increasing peripheral insulin secretion through PPAR&gamma; regulator activity.


---
# Grey and White Matter alterations in Obsessive-Compulsive Personality disorder: a Data Fusion Machine Learning approach

## 强迫型人格障碍的灰质和白质改变: 一种数据融合机器学习方法

Link: https://www.researchsquare.com/article/rs-5721098/latest

Obsessive-Compulsive Personality Disorder (OCPD) is a complex mental condition marked by excessive perfectionism, orderliness, and rigidity, often starting in adolescence or early adulthood; it affects 1.9&amp;ndash;7.8% of the population. The disorder differs from Obsessive-Compulsive Disorder (OCD) for an apparent compromise of personality, distorted self-representation and altered perception of others. Although the two disorders present evident differences, unlike OCD, the neural bases of OCPD are understudied. The few studies conducted so far have identified grey matter alterations in brain regions such as the striatum and prefrontal cortex, but a comprehensive model of its neurobiology, and the eventual contribution of white matter abnormalities, are still unclear. One intriguing hypothesis is that regions ascribed to the Default Mode Network are involved in OCPD, similar to what has been shown for OCD and other anxiety disorders. To test this hypothesis, the grey and white matter images of 30 individuals diagnosed with OCPD (73% female, mean age&amp;thinsp;=&amp;thinsp;29.300), and 34 healthy matched controls (82% female, mean age&amp;thinsp;=&amp;thinsp;25.599) were analyzed with a data fusion unsupervised machine learning method known as Parallel Independent Component Analysis (pICA) to detect the joint contribution of these modalities to the OCPD diagnosis. Results indicated that two gray matter networks (GM5 and GM23) and one white matter network (WM25) differed between the OCPD and the control group. GM5 included brain regions belonging to the Default Mode Network and Salience Network, and was significantly correlated with anxiety; GM-23 included portions of the cerebellum, the precuneus, and the fusiform gyrus; WM-25 included white matter portions adjacent to Default Mode Network regions. These findings shed new light on the grey and white matter contributions to OCPD and may pave the way to developing objective markers of this disorder.


---
# Analysis of Biofilm Assembly by Large Area Automated AFM

## 大面积自动化AFM生物膜组装分析

Link: https://www.researchsquare.com/article/rs-5537963/latest

Biofilms are complex microbial communities critical in medical, industrial, and environmental contexts. Understanding their assembly, structure, genetic regulation, interspecies interactions, and environmental responses is key to developing effective control and mitigation strategies. While Atomic Force Microscopy (AFM) offers critically important high-resolution insights on structural and functional properties at the cellular and even sub-cellular level, its limited scan range and labor-intensive nature restricts the ability to link these smaller scale features to the functional macroscale organization of the films. We begin to address this limitation by introducing an automated large area AFM approach capable of capturing high-resolution images over millimeter-scale areas, aided by machine learning for seamless image stitching, cell detection, and classification. Large area AFM is shown to provide a very detailed view of spatial heterogeneity and cellular morphology during the early stages of biofilm formation which were previously obscured. Using this approach, we examined the adhesion and organization of Pantoea sp. YR343 on PFOTS-treated glass surfaces, as a model system. Our findings reveal a preferred cellular orientation among surface-attached cells, forming a distinctive honeycomb pattern. Detailed mapping of flagella interactions suggests that flagellar coordination plays a role in biofilm assembly beyond initial attachment. Additionally, we utilized large-area AFM to characterize surface modifications on silicon substrates featuring a pillar/ridge architecture. Certain ridge spacings disrupted the honeycomb structures, underscoring the potential of this method for screening surfaces or combinatorial libraries of surface modifications to enhance our understanding and control of bacterial cell attachment and subsequent biofilm formation.


---
# Evaluation of AES-256 Encryption and Machine Learning for Securing GSM Communications against Sniffing Attacks

## 评估AES-256加密和机器学习以保护GSM通信免受嗅探攻击

Link: https://www.researchsquare.com/article/rs-5747899/latest

Long notorious as one of the most popular mobile communication standards to be found around the world, the Global System for Mobile Communications (GSM) has been in widespread use for a long time now. A GSM network has been designed to have security in mind but there is still a large number of security threats to the GSM network including GSM sniffing attacks. GSM attacks rely on the weaknesses in the encryption protocols, such as A5/1, and A5/2 which can be brute forced to succeed. Sensitive data including voice calls, text messages, and location information are at great risk of interception by unauthorized parties and vulnerabilities. This research examines GSM network vulnerabilities, sniffing attacks, and the boundaries of conventional encryption protocols. This analyzes current mitigation strategies and further presents advanced countermeasures, such as mandating the use of AES 256 encryption that offers a more powerful defense against brute force attacks. It also investigates the use of machine learning for real-time detection of sniffing attacks. However, machine learning algorithms can detect unusual network activity and allow timely intervention to prevent unauthorized access. The implications of these attack methodologies and performance metrics are also included in the study, along with a complete analysis of different mitigation strategies and their performance to enhance GSM security. Increasing threats motivate the research to enhance the confidentiality, integrity, and availability of GSM communications.


---
# FSID: A Novel Approach to Human Activity Recognition Using Few-Shot Weight Imprinting

## FSID: 一种使用少镜头重量印记的人类活动识别的新方法

Link: https://www.researchsquare.com/article/rs-5752651/latest

Accurate recognition of activities from gait sensory data is essential for healthcare and wellness monitoring applications. This paper proposes Few-Shot Imprinted DINO (FSID), a new approach for Human Activity Recognition (HAR) in scarce-data settings, combining Few-Shot learning with weight imprinting. The methodology transforms gait sensory signals into spectrograms using the Fourier Transform, enabling the use of deep learning techniques like transfer learning to refine activity classification. FSID extracts meaningful features from generated spectrograms using the DINO model, integrating transfer learning with Few-Shot learning and weight imprinting to effectively classify uncommon or novel activities. Extensive experimentation with diverse datasets, such as HuGaDB and LARa, demonstrates that FSID outperforms current methods, achieving high accuracy and robustness even with limited labeled data. These results confirm that spectrogram representations, together with effective Few-Shot learning integration, enhance the model's scalability and adaptability, making FSID suitable for healthcare applications where data collection may be challenging.


---
# Target and Biomarker Exploration Portal for Drug Discovery

## 用于药物发现的靶标和生物标志物探索门户

Link: https://www.researchsquare.com/article/rs-5784705/latest

The discovery of novel drug targets and precision biomarkers remains a major challenge in drug development, with traditional differential expression analysis often overlooking key regulatory proteins. Here, we present a novel, web-based bioinformatics tool designed to accelerate the drug discovery process by integrating large-scale biomedical data with network analysis techniques. This tool harnesses machine-learning approaches to combine multi-modal datasets, including human genetics, functional genomics, and protein-protein interaction networks, to decode causal disease mechanisms and uncover novel therapeutic targets and precision biomarkers for specific phenotypes. A unique feature of the tool is its ability to process large-scale data in real-time, facilitated by efficient cloud-based architecture. Additionally, the tool incorporates an integrated large language model (LLM), which assists researchers in exploring and interpreting complex biological relationships within the generated networks and multi-omics data. By offering an intuitive, interactive interface, the LLM enhances the exploration of biological insights, making it easier for scientists to derive actionable conclusions. This powerful integration of AI-driven network analysis, multi-omics data, and advanced language models provides a robust framework for accelerating the identification of novel drug targets, ultimately advancing the field of precision medicine. The tool is publicly available at https://pdnet.missouri.edu/.


---
# Two and a half centuries of land reclamation, intensification, and urbanization homogenized northern Belgium landscapes

## 两个半世纪的土地开垦，集约化和城市化同质化比利时北部景观

Link: https://www.researchsquare.com/article/rs-5536645/latest

We quantified historical land-use with deep learning segmentation, applied to tiled historical maps, and identified 3 successive drivers of long-term (1774&amp;ndash;2022) landscape transformation in northern Belgium (13,800 km2). Between 1774 and 1873, land reclamation halved the area of natural and semi-natural land-use. Agricultural intensification was the main driver in the next time interval (1873&amp;ndash;1969), as the area of grassland and orchard doubled at the expense of arable land. Urbanization marked the last time interval (1969&amp;ndash;2022) and reduced agricultural land-use. The reclamation of fertile soils for agriculture and the shift of forests to sand soils previously covered by heathland first increased the association of land-use classes to soil groups. After 1873 this association progressively weakened by expansion of grasslands beyond valleys and polders and urbanization disregarding soils. A sharp rise of land-use interspersion indicated that landscape transformation culminated between 1873 and 1969 and resulted in the homogenization of previously distinct landscapes.


---
# Hydroxide exchange membrane carbon capture using a nickel hydroxide symmetric battery cell

## 使用氢氧化镍对称电池的氢氧化物交换膜碳捕获

Link: https://www.researchsquare.com/article/rs-5627423/latest

Electrochemical carbon capture devices can be a low energy cost solution for direct air capture (DAC) using renewable electricity. Historically electrochemical carbon-capture has targeted a range of concentrations from atmospheric (400 ppmCO2) (DAC),  1  to life-support (5000 ppmCO2),  2  to point-source capture (10% CO2).  3  The hydroxide exchange membrane nickel hydroxide symmetric battery cell with two identical electrodes has low voltage requirements making it more suitable for DAC than other electrochemical approaches. A 25 cm 2  laboratory cell shows an average energy cost of 1.15 MWh&amp;middot;tonCO2 &amp;minus;1 and a CO2 flux of 78 kgCO2&amp;middot;m2&amp;middot;yr&amp;minus;&amp;thinsp;1 at 2 mA&amp;middot;cm&amp;minus;&amp;thinsp;2. A manufacturable 25 cm 2  cell is durability tested for 5000 hours and achieves an energy of 0.46 MWh&amp;middot;tonCO2 &amp;minus;1 and a flux of 62 kgCO2&amp;middot;m2&amp;middot;yr&amp;minus;&amp;thinsp;1 at the end of the test. A DAC pilot system with a stack of 9 scaled-up 300 cm 2  cells demonstrates an energy of 0.83 MWh&amp;middot;tonCO2 &amp;minus;1 and a flux of 75 kgCO2&amp;middot;m2&amp;middot;yr&amp;minus;&amp;thinsp;1 and meets the 300 Pa pressure drop required for DAC.  4  Modular design projects improvements in cost from manufacturing and economies of scale, and a pathway to below 100 $&amp;middot;tonCO2 &amp;minus;1 from learning rates of past energy technologies.  5


---
# Deep learning approach to predict developmental outcomes of non-suicidal self-injury: An ERP study

## 预测非自杀性自伤发展结果的深度学习方法: 一项ERP研究

Link: https://www.researchsquare.com/article/rs-5784879/latest

Background
Identifying predictors of developmental outcomes in non-suicidal self-injury (NSSI) is crucial and goes beyond tracking its progression. EEG technology is notable for its consistent and objective neurophysiological recordings in NSSI detection. Using ERP components in deep learning models for predicting these outcomes is still underexplored.
Methods
Twenty-six in the remission group (RG), twenty-nine in the aggravation group (AG), and twenty-seven in the healthy group (HG) completed the affective Stroop task with EEG. N2 and P3 component differences were analyzed across groups, and the EEGNet model was used to assess NSSI developmental outcomes.
Result
A significant interaction was observed between group and emotion on N2 (F (2, 79) = 16.934, p &amp;lt; 0.001, &eta;2 = 0.300). Under neutral stimuli, N2 was smallest in HG, larger in RG, and largest in AG, while for negative stimuli, N2 in HG was smaller than in RG and AG. A significant group effect on P3 was noted (F (2, 79) = 7.607, p &amp;lt; 0.001, &eta;2 = 0.161), with HG exhibiting larger P3 compared to RG and AG. The N2 under neutral stimuli achieved the highest classification accuracy (94.31%).
Conclusion
The findings indicate that NSSI is linked to cognitive processing deficits, including impaired control and resource allocation to stimuli. Additionally, N2 amplitudes were shown to reliably predict developmental outcomes in NSSI.


---
# MFTD: Multimodal Feature Fusion of Camera and LiDAR for 3D Target Detection

## MFTD: 相机与激光雷达多模态特征融合的三维目标检测

Link: https://www.researchsquare.com/article/rs-5795128/latest

We propose a neural network for multimodal feature fusion in autonomous driving scenarios, which is structured to generate two stages of network-shared features using two modal data: radar point clouds and camera images. The two sub-networks are: the multimodal fusion region suggestion network (MF-RPN) and the secondary target detection network. Our proposed region suggestion network can perform a new architecture of multimodal feature fusion on high-resolution feature maps while generating stable and reliable object frames for multiple object classes of real road scenes. These object frames can provide a more accurate prediction of the range, orientation, and categorization of objects in 3D space for the later second-stage detection network. Experiments demonstrate that our proposed model architecture generates relatively good results on the KITTI up to 3D object detection benchmark. Under the medium difficulty setting, the 3D mean average precision mean (mAP3D) and average orientation similarity (AHS) of the automobile category are as high as 76.47% and 92.45%, which are 7.25% and 1.72% higher than the existing better multimodal detection method EOTL[28], and better than the unimodal DSGN++ [29] and PointRGBNet [30] 3D mean average precision (mAP3D) by 6.31% and 1.13%. In addition, it can effectively reduce the memory footprint and runtime in order to make it suitable for deploying automation on autonomous vehicles, making it one of the optional excellent solutions that can be deployed on self-driving cars.


---
# Brain Tumor Classification in Sustainable Healthcare using Machine Learning

## 使用机器学习在可持续医疗保健中的脑肿瘤分类

Link: https://www.researchsquare.com/article/rs-5795846/latest

In sustainable healthcare, early and accurate diagnosis is crucial in reducing the burden on healthcare systems and improving patient outcomes. This paper explores the application of machine learning techniques, specifically K-Nearest Neighbors (KNN) and Support Vector Classifier (SVC), for classifying brain tumors based on medical imaging data. By leveraging these machine learning methods, we aim to provide an efficient and interpretable solution that maintains high accuracy while optimizing computational resources. Machine learning models, due to their lower resource demands, are more suitable than deep learning approaches for sustainable healthcare environments, particularly in scenarios with limited infrastructure. The proposed models are validated through cross validation and hyperparameter tuning to achieve optimal performance. Our results demonstrate the potential of machine learning in brain tumor classification, offering a balance between accuracy and sustainability, and paving the way for more scalable and accessible diagnostic systems.


---
# Enhancing Quantum Key Distribution Efficiency and Security

## 提高量子密钥分发效率和安全性

Link: https://www.researchsquare.com/article/rs-5794508/latest

Quantum Key Distribution (QKD) is a cornerstone of next-generation cryptographic technologies, offering unparalleled security by utilizing the principles of quantum mechanics. However, practical implementations of QKD face significant challenges, including inefficiencies in key generation, susceptibility to noise, and vulnerabilities to eavesdropping. This work addresses these challenges by proposing a machine learning (ML)-driven approach to optimize QKD protocols, focusing on enhancing both efficiency and security. In this work it is intended to evaluate three advanced protocols Adaptive, Entanglement-Based, and Hybrid under varying conditions such as key length, noise levels, and channel stability. The ML models will include ensemble learning models namely Random Forest and XGBoost, the models will analyze the impact of key parameters on protocol performance and predict efficiency with high accuracy. The results reveal that the Adaptive protocol significantly outperforms the Entanglement-Based and Hybrid protocols, achieving an efficiency of up to 0.80 for a key length of 2500 bits, compared to 0.24 for the Entanglement-Based protocol and 0.26 for the Hybrid protocol. The Adaptive protocol also demonstrates superior detection probability (ranging from 0.84 to 0.85) and a higher probability of detecting eavesdropping (ranging from 0.43 to 0.45). Furthermore, correlation analysis shows a strong positive relationship (r&amp;thinsp;=&amp;thinsp;0.9985) between key length and efficiency for the Adaptive protocol, highlighting its scalability. In contrast, the Entanglement-Based protocol shows consistent but lower performance across all metrics, while the Hybrid protocol offers a compromise but remains less efficient than the Adaptive protocol. By integrating ML with quantum cryptography, this work bridges the gap between theoretical advancements and practical implementations, providing a scalable framework for optimizing QKD systems in real-world applications. The findings underscore the importance of protocol design and optimization in achieving secure and efficient quantum communication, paving the way for the quantum internet of the future.


---
# Changes in Functional Brain Connectivity of Electroencephalography while Learning to Touch-type

## 学习触摸类型时脑电图功能脑连接的变化

Link: https://www.researchsquare.com/article/rs-5799272/latest

The functional brain connectivity of electroencephalography (EEG) data that was acquired during the process of learning how to touch-type using the Colemak keyboard distribution is analyzed in this paper. The partial directed coherence (PDC) of the EEG alpha, beta, and gamma rhythms was used to assess the functional brain connectivity at different learning stages. As result, connectivity patterns common to the volunteers of the learning process are found as representative of underlying brain processes. In particular, functional connectivity within alpha brain rhythm in low-difficulty learning tasks exhibit greatest desynchronization in the parietal lobes, which may be an indication of good performance during those tests. Widespread increase of fronto-central brain connectivity in the alpha band during the high-difficulty lesson is shown as a reflection of refined attention allocation and effective motor program processing. Beta modulation during motor planning is also reflected through an increase of frontal functional connectivity, as well as repetition suppression by a decrease in gamma connectivity. Finally, the use of metrics from complex network theory allowed to associate channels P4, F4, Cz, and C4 as important to processes such as attention, execution of motor sequences, cognitive performance and focused attention. These results add insight to previous analysis performed on the same database and further proves the feasibility of monitoring a learning process with EEG.


---
# GPT vs Human Legal Texts Annotations: A Comparative Study with Privacy Policies

## GPT与人类法律文本注释: 与隐私政策的比较研究

Link: https://www.researchsquare.com/article/rs-5799153/latest

High-quality corpora of annotated privacy policies are scarce, yet essential for training, testing, and evaluating accurate machine learning models. However, elaborating new corpora remains an error-prone and resource-intensive task, heavily reliant on highly specialized and hard-to-find human annotators. Recent advancements in Generative Pre-trained Transformers (GPTs) open the possibility of using them to annotate privacy policies with performance comparable to that of human annotators, thereby streamlining the process while reducing human resource demands. This paper presents a novel method for annotating privacy policies based on a codebook, a well-designed prompt, and the analysis of logarithmic probabilities (logprobs) of a GPT's output tokens during the annotation process. We validated our method using the GPT-4o model and the well-known, open, multi-class, and multi-label OPP-115 corpus, achieving performance comparable to 80% of human annotators in segment-level annotation and matching 90% of human annotators in a full-text level annotation. Furthermore, incorporating logprobs analysis allowed the method to match the performance of all human annotators in full-text level annotation, suggesting that context enhances the task. These findings demonstrate the potential of our method to automate annotations with performance similar to human annotators while significantly reducing resource demands.


---
# Heart Failure Detection in Electrocardiograms Using Artificial Intelligence

## 使用人工智能检测心电图中的心力衰竭

Link: https://www.researchsquare.com/article/rs-5716430/latest

The diagnosis of heart failure (HF) is resource-intensive, requiring specialized personnel and equipment, which often leads to severe underdiagnosis. This study proposes the use of a machine learning model to detect HF in Electrocardiograms (ECGs), a commonly used tool in most healthcare settings. HF is known to have limited validity in diagnosis codes, limiting the viability of direct application of supervised learning. However, we hypothesize that validating diagnosis with measured levels of circulating N-terminal proB-type natriuretic peptide (NT-proBNP), ameliorates the impact of label noise in a large dataset. We demonstrate the success of the labelling strategy by developing a neural network and prospectively validating it in a cohort comprising 43109 patients. The model significantly outperformed NT-proBNP in diagnostic accuracy (p = 7.5e-7), and is capable of detecting both HF with reduced ejection fraction (AUC=0.91) and preserved ejection fraction (AUC=0.68-0.89 depending on definition). To highlight the impact of underdiagnosis in evaluating the model, we conducted a small-scale retrospective clinical evaluation of the test set, including patients with ejection fraction &gt;50% with no HF diagnosis and normal levels of NT-proBNP. In this subgroup, 24 out of the 30 patients with the highest model-predicted risk satisfied the diagnostic criteria for HFpEF. These combined findings demonstrate the model&rsquo;s capability in finding HF independent of ejection fraction, and a potential for accessible diagnostics through AI-enhanced ECG analysis.


---
# Deep Data-Driven Neural Network for Malaria Vaccination

## 用于疟疾疫苗接种的深度数据驱动神经网络

Link: https://www.researchsquare.com/article/rs-5789145/latest

Malaria still remains a significant global health challenge that requires innovative strategies for its control and eventual eradication. In this article, we present a malaria vaccination model to assess and predict the effects of vaccination interventions. The model parameters are learned via feedforward Neural Network. We employed Residual Neural Network and Recurrent Neural Networks(GRU, LSTM, and BiLSTM) to predict and forecast daily and sequential malaria cases using generated data from the Ghana vaccination population.&amp;nbsp;


---
# An integrated microwave neural network for broadband computation and communication

## 用于宽带计算和通信的集成微波神经网络

Link: https://www.researchsquare.com/article/rs-5494383/latest

High-bandwidth applications, from multi-gigabit communication and high-performance computing to radar signal processing, demand ever-increasing processing speeds. However, they face limitations in signal sampling and computation due to hardware and power constraints. In the microwave regime, where operating frequencies exceed the fastest clock rates, direct sampling becomes difficult, prompting interest in neuromorphic analog computing systems. We present the first demonstration of direct broadband frequency domain computing using an integrated circuit that replaces traditional analog and digital interfaces. This features a Microwave Neural Network (MNN) that operates on signals spanning tens of gigahertz, yet reprogrammed with slow, 150 MBit/sec control bitstreams. By leveraging significant nonlinearity in coupled microwave oscillators, features learned from a wide bandwidth are encoded in a comb-like spectrum spanning only a few gigahertz, enabling easy inference. We find that the MNN can search for bit sequences in arbitrary, ultra-broadband
10 GBit/sec digital data, demonstrating suitability for high-speed wireline communication.
Notably, it can emulate high-level digital functions without custom on-chip circuits, potentially replacing power-hungry sequential logic architectures. Its ability to track frequency changes over long capture times also allows for determining flight trajectories from radar returns. Furthermore, it serves as an accelerator for radio-frequency machine learning, capable of accurately classifying various encoding schemes used in wireless communication. The MNN achieves true, reconfigurable broadband computation, which has not yet been demonstrated by classical analog modalities, quantum reservoir computers using superconducting circuits, or photonic tensor cores, and avoids
the inefficiencies of electro-optic transduction. Its sub-wavelength footprint in a Complementary Metal-Oxide-Semiconductor process and sub-200 milliwatt power consumption enable seamless integration as a general-purpose analog neural processor in microwave and digital signal processing chips.

